# Uberduck Tacotron 2 Multi-speaker + GST (PyTorch) Implementation

This is a notebook from Kaggle I had made that allows user's to make their own AI voices using 16bit PCM, 22050 HZ WAV files on the Neural networks provided by NVIDIA's creation of Tacotron 2 which has been further developed and worked on by the team at Uberduck.ai in order to add other amazing features to it such as multi-speaker and GSTs. These AI text to speech voices can be used to output synthesised vocals that will have the emotions of the output audio read and displayed via emojis or you could overwrite the emotions set on the output audio to make it seem more realistic (emotional synthesis).

You will need a dataset including 22,050hz, 16 bit, PCM Wav files. You will also need a transcription file and/or a validation file too in order to train a model.

Further instructions can be found within the notebook.
