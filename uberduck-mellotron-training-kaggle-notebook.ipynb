{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# **Uberduck Mellotron Training (Kaggle Notebook)**\n---\n<a href=\"https://github.com/uberduck-ai/uberduck-ml-dev\"> Uberduck Mellotron </a> & original Mellotron repo<a href=\"https://github.com/NVIDIA/mellotron\"> Mellotron </a> | **Created by <a href=\"https://github.com/ColdFir5\"> Michael </a>**, **Massive thanks to <a href=\"https://github.com/johnpaulbin\"> johnpaulbin </a> for helping put together the components for this notebook, and the rest of the uberduck development team**\n\nThis notebook will require: **A dataset**\n\nThe dataset should look like this: \n\n```\nKaggle Dataset/\n          ├──wavs/\n          │    ├──1.wav\n          │    ├──2.wav\n          │    ├──3.wav\n          │    └──etc\n          └──transcription.txt\n               ├──wavs/1.wav|This is a test number 1!\n               ├──wavs/2.wav|This is a test number 2!\n               └──etc\n```\n\n**MAKE SURE 'GPU' HAS BEEN SELECTED AS THE ACCELERATOR IN THE NOTEBOOK SETTINGS**\n\n*Updated 24/10/21 VERSION 3-5: Bugs fixed*\n\n**The project is still under development and the notebook will be tweaked and updated overtime, be sure to check for updates!**\n\n---\n# TRAINING INSTRUCTIONS\n* **Make sure to make your own version of this notebook for each new model**\n* **Import your dataset (22050hz, Mono, 16bit PCM audio) in the top right corner of the screen**\n* **Transcription file should look be in this format for each wav (WITH PUNCTUATION):**```wavs/1.wav|[Text here].```\n* **RUN ALL**\n* **Fill in required inputs**\n* **Follow though all steps**\n* ***(VERY IMPORTANT)*** Once your model has been trained **DO NOT FORGET TO SAVE VERSION AND GO TO 'ADVANCED' AND CHECK 'ALWAYS SAVE OUTPUT'** so you do NOT LOSE progress\n---\n# CONTINUING TO TRAIN?\n\n*Coming soon potentially*\n\n---","metadata":{}},{"cell_type":"markdown","source":"# **1) User inputs**\n\nEnter the name of your dataset and transcription file (with file extension)","metadata":{}},{"cell_type":"code","source":"# Variables\ndataset_name = \"none\"\ntranscript_file_name = \"none\"\n\n# Inputs\nwhile dataset_name == \"none\":\n    dataset_name = input(\"What is the name of your dataset?: \")\n\nwhile transcript_file_name == \"none\":\n    transcript_file_name = input(\"What is the name of your training transcription file (add file extention: eg .txt)?: \")\n\n# User Completion\nprint(\"Step 1 Completed.\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **2) Clone Git Repo and install requirements & download LJSpeech model**\n\nThe LJSpeech model is to warm start the process","metadata":{}},{"cell_type":"code","source":"# Clone repository \n!git clone -q https://github.com/uberduck-ai/uberduck-ml-dev\n\n# Go into the main directory for mellotron\n%cd uberduck-ml-dev\n\n# Install requirements\n!pip install -e .\n\n# Download LJspeech model\n!pip install gdown\n!gdown --id 1UwDARlUl8JvB2xSuyMFHFsIWELVpgQD4\n\n# User Completion\nprint(\"Step 2 Completed.\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **3) Transfer dataset over to working env**","metadata":{}},{"cell_type":"code","source":"# Import libraries\nimport os\n\n# Move dataset into working environment\nos.system(f'cp -a ../../input/{dataset_name} /kaggle/working/uberduck-ml-dev')\n\n# User Completion\nprint(\"Step 3 Completed.\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **4) Edit transcript to Mellotron's transcription file format**\n\n* Adds the full file directory hierarchy\n* Adds ```|0``` to the end of the line for multispeaker formatting\n* e.g. ```/kaggle/working/uberduck-ml-dev/dataset/wavs/1.wav|This is a test!|0```","metadata":{}},{"cell_type":"code","source":"# Open the transcription file and edit the file to Mellotron's format\nwith open(f\"../../input/{dataset_name}/{transcript_file_name}\") as f:\n    # Open the transcription file in working area with 'write' permissions\n    with open(f\"{dataset_name}/{transcript_file_name}\", \"w\") as f1:\n        for line in f:\n            # Write newly edited lines to the transcription file (Overwrite)\n            transcript_line = f\"/kaggle/working/uberduck-ml-dev/{dataset_name}/{line[:-1]}|0\\n\"\n            f1.write(transcript_line)\n    \n    # Re-open the transcription file with new edits and delete the last line which is empty\n    transcript_file = open(f\"{dataset_name}/{transcript_file_name}\")\n    transcript_file_lines = transcript_file.readlines()\n    transcript_file_lines = transcript_file_lines[:-1]\n    transcript_file_lines.append(transcript_line[:-1])\n    transcript_file.close()\n    \n    # Re-save transcription file\n    with open(f\"{dataset_name}/{transcript_file_name}\", \"w\") as transcript_file:\n        for line in transcript_file_lines:\n            transcript_file.write(line)\n            \n# User Completion\nprint(\"Step 4 Completed.\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **5) Convert text file transcription to Arpa**","metadata":{}},{"cell_type":"code","source":"# Import libraries and install resources\nimport os\n!pip install inflect\n\n# Download the Arpa dictionary\nif not os.path.exists(\"/kaggle/working/uberduck-ml-dev/merged.dict.txt\"):\n    !wget \"https://github.com/johnpaulbin/tacotron2/releases/download/Main/merged.dict.txt\"\n\n# Move the python file into the working directory\nos.system(f'cp -a ../../input/arpabet/ /kaggle/working/')\n\n# Converts text into Arpa and saves the new file\nos.system(f\"python /kaggle/working/arpabet/convert_arpabet.py --file='/kaggle/working/uberduck-ml-dev/{dataset_name}/{transcript_file_name}'\")\n\n# User Completion\nprint(\"Step 5 Completed.\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **6) Assign settings to configuration file**","metadata":{}},{"cell_type":"code","source":"# Import libraries\nimport json\n\n# Assign variables\nbatch_size_num = 0\ncharacter_name = \"\"\nepoch_num = 0\ncheckpoint_num = 0\n\n# User inputs (with validation check)\nwhile batch_size_num <= 0:\n    batch_size_num = int(input(\"What batch size would you like to use (recommended: 24): \"))\n\nwhile character_name == \"\":  \n    character_name = input(\"What is the name of your character?: \")\n\nwhile epoch_num <= 0:\n    epoch_num = int(input(\"How many epoch would you like to train your model to? (recommended: 5000): \"))\n    \nwhile checkpoint_num <= 0:\n    checkpoint_num = int(input(\"How often would you like to save a version of your model (recommended: 500): Epoch - \"))\n\n# Add \"ARPA\" to the end of the filename for config file\nlisttranscript_file_name = transcript_file_name.split(\".\")\nlisttranscript_file_name[0] = f\"{listtranscript_file_name[0]}ARPA\"\n\narpatranscript_file_name = \".\".join(listtranscript_file_name)\n\n# Open the config file and edit values\nwith open('tacotron2_config.json') as f:\n    json_config = json.load(f)\n    json_config[\"batch_size\"] = batch_size_num\n    json_config[\"checkpoint_name\"] = character_name\n    json_config[\"checkpoint_path\"] = \"/kaggle/working/checkpoint\"\n    json_config[\"dataset_path\"] = f\"/kaggle/working/uberduck-ml-dev/{dataset_name}\"\n    json_config[\"warm_start_name\"] = \"mellotron_ljs.pt\"\n    json_config[\"epochs\"] = epoch_num\n    json_config[\"include_f0\"] = True\n    json_config[\"n_speakers\"] = 1\n    json_config[\"fp16_run\"] = False\n    json_config[\"n_frames_per_step_initial\"] = 1\n    json_config[\"epochs_per_checkpoint\"] = checkpoint_num\n    json_config[\"training_audiopaths_and_text\"] = f\"/kaggle/working/uberduck-ml-dev/{dataset_name}/{arpatranscript_file_name}\"\n    json_config[\"val_audiopaths_and_text\"] = f\"/kaggle/working/uberduck-ml-dev/{dataset_name}/{arpatranscript_file_name}\"\n    json_config.update({f\"ignore_layers\": None})\n                         \n# Save the JSON files with new updated values\nwith open('tacotron2_config.json', 'w') as JSON_FILE:\n    json.dump(json_config, JSON_FILE)\n                         \n# User Completion\nprint(\"Step 6 Completed.\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **7) Train Mellotron model**\n\nTrains your Mellotron model using the newly edited configuration file","metadata":{}},{"cell_type":"code","source":"# Train model using config file\n!bash train.sh \"tacotron2_config.json\"\n\n# User Completion\nprint(\"Step 7 Completed.\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}