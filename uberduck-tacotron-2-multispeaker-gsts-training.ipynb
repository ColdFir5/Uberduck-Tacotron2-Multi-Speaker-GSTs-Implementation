{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# **Tacotron 2 (Multi-speaker) + TorchMoji Model Training (Kaggle Notebook)**\n---\n<a href=\"https://github.com/uberduck-ai/uberduck-ml-dev\"> Uberduck Tacotron 2 (Multispeaker) + GSTs repo</a> & <a href=\"https://github.com/NVIDIA/tacotron2\"> original tacotron 2 repo </a> | **Created by <a href=\"https://github.com/ColdFir5\"> Michael </a>, Credits to <a href=\"https://www.kaggle.com/johnpaulk\"> johnpaulbin </a> for helping put together step 8 for making tensorboard work on kaggle properly.**\n\nThis notebook will require: **A dataset**\n\nThe dataset should look like this: \n\n```\nKaggle Training Dataset/\n          ├──wavs/\n          │    ├──1.wav\n          │    ├──2.wav\n          │    ├──3.wav\n          │    └──etc\n          └──transcription.txt\n               ├──wavs/1.wav|This is a test number 1!\n               ├──wavs/2.wav|This is a test number 2!\n               └──etc\n```\n\n**MAKE SURE 'GPU' HAS BEEN SELECTED AS THE ACCELERATOR IN THE NOTEBOOK SETTINGS**\n\n*UPDATED 14/02/22, VERSION 6: Completely revamped and updated the notebook*\n\n*UPDATED 14/02/22, VERSION 7: Fixed a bug*\n\n*UPDATED 14/02/22, VERSION 8: Added a fix for the ```GLIBCXX_3.4.26 not found``` issue*\n\n#### ***UPDATED 15/02/22, VERSION 9: Added TorchMoji! You can now train your models and it will predict emotion while training and give you the chance to set emotion while synthesising!***\n\n*UPDATED 15/02/22, VERSION 10: Added the config file to the zipping process on step 10*\n\n*UPDATED 18/02/22, VERSION 11: Minor fix*\n\n---\n# TRAINING INSTRUCTIONS\n* Make sure to make your own version of this notebook for each new model\n* **Import your dataset (22050hz, Mono, 16bit PCM audio) in the top right corner of the screen**\n* Transcription file should look be in this format (LJS Formatting) for each wav (WITH PUNCTUATION):```wavs/1.wav|[Text here].```\n* **RUN ALL STEPS INDIVIDUALLY AND MAKE SURE TO READ EACH STEP CAREFULLY**\n* Fill in required inputs\n* ***(VERY IMPORTANT)*** Once your model has been trained **DO NOT FORGET TO SAVE VERSION AND GO TO 'ADVANCED' AND CHECK 'ALWAYS SAVE OUTPUT'** so you do NOT LOSE progress\n* ***(VERY IMPORTANT)*** Notebooks run for **12 hours at a time**, be sure to **save or download your models** at least **15 minutes before** the end\n---\n# CONTINUING TO TRAIN?\n\n* **Be sure to change the ```warm_start_name``` to your latest trained model name (with the directory if required)**\n* *Working on making this potentially be automatic, no promises ;)*\n\nThe dataset to use when continuing to train should look like this:\n\n```\nKaggle Model Dataset/\n          ├──checkpoints/\n          │    └──tacotron2_3250.pt\n          │\n          └──runs/\n               ├──events.out.tfevents.5239647356.gh52845952r9\n               └──etc\n```\np.s. When downloading your file after training they will be in this format already\n\n---","metadata":{}},{"cell_type":"markdown","source":"# **1) User inputs**\n\nEnter the name of your dataset, transcription file (with file extension), and if you are continuing with training or starting fresh","metadata":{}},{"cell_type":"code","source":"# Variables\ndataset_name = \"none\"\ntranscript_file_name = \"none\"\ntraining = \"none\"\nmodels_dataset_name = \"none\"\n\n# Inputs\nwhile dataset_name == \"none\":\n    dataset_name = input(\"What is the name of your training dataset?: \")\n\nwhile transcript_file_name == \"none\":\n    transcript_file_name = input(\"What is the name of your training transcription file (add file extention: eg .txt)?: \")\n    \nwhile training not in (\"Continue\",\"New\",\"C\",\"N\"):\n    print(\"Please type either 'Continue' or 'New'\")\n    training = input(\"Do you wish to continue training your model or start a new? [Continue/New]: \").title()\n    \nif training in (\"C\",\"Continue\"):\n    while models_dataset_name == \"none\":\n        models_dataset_name = input(\"What is the name of your dataset within Kaggle to continue with training?: \")\n\n# User Completion\nprint(\"---------------------------------------\\nStep 1 completed\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **2) Install the Git Repo + the requirements**","metadata":{}},{"cell_type":"code","source":"# Download the repo requirements \n!pip install -q git+https://github.com/johnpaulbin/uberduck-ml-dev.git --upgrade\n\n# Make a new folder called \"project\"\n!mkdir project/\n\n# Open the newly created directory\n%cd project/\n\n# User Completion\nprint(\"---------------------------------------\\nStep 2 completed\")","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **2.1) Download pre-trained model & Torchmoji model with vocab file**\n\nThe pre-trained model provided is to warm start the process of training a new model with torchmoji embeddings meaning the ability to predict emotion while training and set emotion to audio synthesis!","metadata":{}},{"cell_type":"code","source":"# Download a pre-trained model to warm start with\n!wget \"https://github.com/johnpaulbin/uberduck-ml-dev/releases/download/v1/tacotron2_statedict.pt\" -O tacotron2_statedict.pt\n\n# Download torchmoji trained model\n!wget \"https://github.com/johnpaulbin/torchMoji/releases/download/files/pytorch_model.bin\" -O torchmoji_model.bin\n\n# Download the vocab file for torchmoji\n!wget \"https://raw.githubusercontent.com/johnpaulbin/torchMoji/master/model/vocabulary.json\" -O vocabulary.json\n\n# User Completion\nprint(\"---------------------------------------\\nStep 2.1 completed\")","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **3) Transfer dataset over to working env**\n\nWhen moving your transcription file over it automatically renames it to ```train_filelist.txt```","metadata":{}},{"cell_type":"code","source":"# Import Libraries\nimport os\n\n# Move all files to the working environment\nos.system(f'cp -a ../../input/{dataset_name}/wavs /kaggle/working/project/')\nos.system(f'cp -a ../../input/{dataset_name}/{transcript_file_name} /kaggle/working/project/train_filelist.txt')\n\n# User Completion\nprint(\"---------------------------------------\\nStep 3 completed\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **4) Continuing to train? Transfers model and logs into the working directory**","metadata":{}},{"cell_type":"code","source":"# Check if they are continuing with training\nif training in (\"C\",\"Continue\"):\n    os.system(f'cp -a ../../input/{models_dataset_name}/checkpoints /kaggle/working/project/')\n    os.system(f'cp -a ../../input/{models_dataset_name}/runs /kaggle/working/project/')\nelse:\n    print(\"You are training a new model meaning there will be no need for further file transfers.\")\n    \n# User Completion\nprint(\"---------------------------------------\\nStep 4 completed\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **5) Edit transcription file to multi-speaker format**\n\n* Adds the full file directory hierarchy\n* Adds ```|0``` (single speaker) to the end of the line for multi-speaker formatting \n* e.g. ```/kaggle/working/project/wavs/1.wav|This is a test!|0```\n\n#### If you want to train more than one speaker, I would recommend that you skip this step and you manually edit your transcription file to have the appropriate ```|0``` ```|1``` ```|2``` ```|3``` suffixes.","metadata":{}},{"cell_type":"code","source":"# Create a copy of the training transcription list\nos.system(f\"cp -a train_filelist.txt train_filelist_copy.txt\")\n\n# Open the transcription file and edit the file to the multi-speaker format\nwith open(f\"train_filelist_copy.txt\") as f:\n    # Open the transcription file in working area with 'write' permissions\n    with open(f\"train_filelist.txt\", \"w\") as f1:\n        for line in f:\n            # Write newly edited lines to the transcription file (Overwrite)\n            transcript_line = f\"/kaggle/working/project/{line[:-1]}|0\\n\"\n            f1.write(transcript_line)\n    \n    # Re-open the transcription file with new edits and delete the last line which is empty\n    transcript_file = open(\"train_filelist.txt\")\n    transcript_file_lines = transcript_file.readlines()\n    transcript_file_lines = transcript_file_lines[:-1]\n    transcript_file_lines.append(transcript_line[:-1])\n    transcript_file.close()\n    \n    # Re-save transcription file\n    with open(\"train_filelist.txt\", \"w\") as transcript_file:\n        for line in transcript_file_lines:\n            transcript_file.write(line)\n            \n# Remove the copy of the transcription list as it will no longer be needed\n!rm train_filelist_copy.txt\n\n# User Completion\nprint(\"---------------------------------------\\nStep 5 completed\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **6) Assign settings to configuration file**\n\n### Notes:\n- Change ```n_speakers``` if running multi-speaker to the number of speakers you will have.\n- Do NOT change ```training_audiopaths_and_text``` and ```val_audiopaths_and_text``` as these have been set already.\n\n### If you want to train a multispeaker model:\n- Add your ```sample_inference_speaker_ids``` in a list, e.g: ```[0, 1, 2, 3]```\n\n### If you want to continue training a model:\n- Change ```warm_start_name``` to your latest trained model name (with the directory, e.g. ```checkpoints/tacotron2_3250.pt```)\n- Change ```ignored_layers``` to ```[\"null\"]```\n\n","metadata":{}},{"cell_type":"code","source":"%%writefile tacotron2_config.json\n{\n    \"batch_size\": 18,\n    \"checkpoint_name\": \"uberduck_model\",\n    \"checkpoint_path\": \"checkpoints\",\n    \"cudnn_enabled\": true,\n    \"dataset_path\": \".\",\n    \"debug\": false,\n    \"distributed_run\": false,\n    \"epochs\": 5001,\n    \"epochs_per_checkpoint\": 50,\n    \"fp16_run\": false,\n    \"include_f0\": false,\n    \"learning_rate\": 5e-4,\n    \"log_dir\": \"runs\",\n    \"n_speakers\": 1,\n    \"p_arpabet\": 1.0,\n    \"has_speaker_embedding\": true,\n    \"sample_inference_speaker_ids\": [0],\n    \"sample_rate\": 22050,\n    \"steps_per_sample\": 50,\n    \"text_cleaners\": [\"english_cleaners\"],\n \n \n    \"training_audiopaths_and_text\": \"train_filelist.txt\",\n    \"val_audiopaths_and_text\": \"train_filelist.txt\",\n \n\n    \"warm_start_name\": \"tacotron2_statedict.pt\",\n    \"ignore_layers\": [\"speaker_embedding.weight\"],\n    \"seed\": 123,\n    \"gst_dim\": 2304,\n    \"gst_type\": \"torchmoji\",\n    \"torchmoji_vocabulary_file\":\"vocabulary.json\",\n    \"torchmoji_model_file\": \"torchmoji_model.bin\"\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **8) Connect ngrok in order to use tensorboard (OPTIONAL)**\n\n- Obtain your auth token from ngrok though: https://dashboard.ngrok.com/get-started/setup\n\n- Once obtained, paste it in the section below where it says ```YOURTOKEN```\n\n- Then run the block of code\n\n**DO NOT CHANGE ANYTHING ELSE**","metadata":{}},{"cell_type":"code","source":"# Import Libraries\nimport os\nimport multiprocessing\n\n# Open project directory\n%cd project\n\n# Variable to hold your auth token\nngrok_auth_token = \"YOURTOKEN\"\n\n# If the zip doesn't exist, then download it\nif not os.path.exists(\"/kaggle/working/project/ngrok-stable-linux-amd64.zip\"):\n    # Download the zip and unzip it\n    !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n    !unzip ngrok-stable-linux-amd64.zip\n\n# Login to ngrok using your auth token\n!./ngrok authtoken \"$ngrok_auth_token\"\n\n# Run tensorboard on ngrok to monitor your progress\npool = multiprocessing.Pool(processes = 10)\nresults_of_processes = [pool.apply_async(os.system, args=(cmd, ), callback = None )\n                        for cmd in [\n                        f\"tensorboard --logdir ./runs/ --host 0.0.0.0 --port 6006 &\",\n                        f\"./ngrok http 6006 &\"\n                        ]]\n\n# Display link for tensorboard\nprint(\"Connect to your tensorboard through this link:\")\n!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n        \n# User Completion\nprint(\"---------------------------------------\\nStep 8 completed\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **9) Train Tacotron 2 Multi-Speaker + TorchMoji model**\n\nTrains your model using the newly created configuration file","metadata":{}},{"cell_type":"code","source":"# Opens project directory\n%cd project\n\n# Trains model using the configuration file\n!python -m uberduck_ml_dev.exec.train_tacotron2 --config \"tacotron2_config.json\"\n\n# User Completion\nprint(\"---------------------------------------\\nStep 9 completed\")","metadata":{"scrolled":true,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **9.1) Run the block of code below ONLY if you recieve an error saying ```GLIBCXX_3.4.26 not found``` while attempting to train**\n\n* This downloading and installing process will take a couple of minutes\n* Please be patient and wait for it to finish\n* **Once finished run step 9 again**\n","metadata":{}},{"cell_type":"code","source":"# Install all required fixes to allow the training prcoess to run smoothly\n!apt-get install sudo > /dev/null\n!sudo add-apt-repository -y ppa:ubuntu-toolchain-r/test > /dev/null\n!sudo apt-get -y dist-upgrade > /dev/null\n!strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep GLIBCXX\n\n# User Completion\nprint(\"---------------------------------------\\nStep 9.1 completed\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# **10) Download model + logs**\n\n* Click the download link located below once step 10 has finished executing in order to download your zip containing your **latest version of your model** and all your logs\n\n* After uploading your model to your Google Drive, you can synthesize your model <a href=\"https://colab.research.google.com/drive/1g9W1stWS6RdeLT9PT5vIgXk_C19fnSx9?usp=sharing#scrollTo=Ye6XioU1TNvf\"> here.</a>\n\n### <a href=\"../tacotron2_files.zip/\"> Download</a>","metadata":{}},{"cell_type":"code","source":"# Import libraries\nimport glob\nimport re\nimport os\n\n# Open project directory\n%cd project\n\n# Function to find latest trained model\ndef latest_model_iteration():\n  # Get all generative models loaded into a list\n  model_list = glob.glob(\"./checkpoints/tacotron2_*.pt\")\n\n  # Create new list for all iteration numbers of models\n  model_iterations = []\n\n  # Loop through list of models and obtain the iteration number\n  for model in model_list:\n    # Finds the iteration number of identified model\n    iteration_num = re.findall(\"[0-9]\",model)\n    \n    # Remove the first \"2\"\n    iteration_num = iteration_num[1::]\n\n    # Add iteration number to the list of model iterations avaliable\n    model_iterations.append(\"\".join(iteration_num))\n\n  # Sort the model iterations list from high to low\n  model_iterations = sorted(model_iterations, reverse=True)\n\n  # Return back the highest model iteration number\n  return model_iterations[0]\n\n# Assign varible to none\ndownload_ready = \"none\"\n\n# Check to see if they want to zip up their files ready to download\nwhile download_ready not in (\"Y\",\"N\",\"Yes\",\"No\"):\n    download_ready = input(\"Are you ready to begin zipping your files to download? [Yes/No]: \").title()\n\n# If they are ready to zip and download\nif download_ready in (\"Yes\",\"Y\"):\n    # Assigns variable the latest model iteration number\n    model_iteration = latest_model_iteration()\n    \n    # Check if zip file exists, if yes then delete if no then make new zip file\n    if os.path.exists(\"/kaggle/working/project/tacotron2_files.zip\"):\n        !rm ../tacotron2_files.zip\n    \n    # Zip files with maximum level of compression\n    os.system(f\"zip -9 -r ../tacotron2_files.zip checkpoints/tacotron2_{model_iteration}.pt runs tacotron2_config.json\")\n\n# User Completion \nprint(\"---------------------------------------\\nStep 10 completed\")","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}